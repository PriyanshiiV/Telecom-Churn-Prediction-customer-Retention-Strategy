{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d1f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\priyanshi\\new folder\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: schedule in c:\\users\\priyanshi\\new folder\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\priyanshi\\new folder\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\priyanshi\\new folder\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\priyanshi\\new folder\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\priyanshi\\new folder\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\priyanshi\\new folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8574be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ telecom_raw.csv saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the dataframe with your telecom data\n",
    "data = {\n",
    "    \"customer_id\": [1001, 1002, 1003, 1004, 1005],\n",
    "    \"data_used_gb\": [5.2, None, 7.8, 15.6, 3.4],\n",
    "    \"calls_made\": [25, 40, 32, 55, 18],\n",
    "    \"revenue_inr\": [180, 280, 210, None, 120],\n",
    "    \"region\": [\"delhi\", \"Mumbai\", \"chennai\", \"DELHI\", \"Kolkata\"],\n",
    "    \"date\": [\"2025/09/25\", \"2025-09-25\", \"25-09-2025\", \"2025-09-25\", \"2025-09-25\"]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "telecom_df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "telecom_df.to_csv(\"telecom_raw.csv\", index=False)\n",
    "\n",
    "print(\"✅ telecom_raw.csv saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49368129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import schedule\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ddb2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up file paths\n",
    "\n",
    "RAW_PATH = \"telecom_raw.csv\"\n",
    "OUT_DIR  = \"output\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"telecom_cleaned.csv\")\n",
    "TMP_PATH = os.path.join(OUT_DIR, \"telecom_cleaned.tmp.csv\")\n",
    "LOG_PATH = os.path.join(OUT_DIR, \"etl_run.log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d720ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates output folder\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "#Logs function\n",
    "def log(msg: str):\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{ts}] {msg}\\n\")\n",
    "    print(f\"[{ts}] {msg}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e71108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning function\n",
    "def clean_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    " \n",
    "   \n",
    "# 1) Standardize text columns - Fix text formatting\n",
    "    if \"region\" in df.columns:\n",
    "        df[\"region\"] = df[\"region\"].astype(str).str.strip().str.title()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 2) Fill missing numeric values with robust medians – missing numbers\n",
    "\n",
    "    for col in [\"data_used_gb\", \"calls_made\", \"revenue_inr\"]:\n",
    "        if col in df.columns:\n",
    "            if pd.api.types.is_numeric_dtype(df[col]) is False:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "\n",
    "    # 3) Parse date; coerce + fill default - Fix date problems\n",
    "\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "        df[\"date\"] = df[\"date\"].fillna(pd.Timestamp(\"2025-09-25\"))\n",
    "\n",
    "    # 4) De-duplicate but keep first; log how many were removed - Remove duplicates\n",
    "\n",
    "    if {\"customer_id\", \"date\"}.issubset(df.columns):\n",
    "        before = len(df)\n",
    "        df = df.drop_duplicates(subset=[\"customer_id\", \"date\"], keep=\"first\")\n",
    "        log(f\"Deduplicated: removed {before - len(df)} duplicate row(s).\")\n",
    "\n",
    "    # 5) Clip clearly invalid ranges (safety net) - Keep data realistic\n",
    "\n",
    "    if \"data_used_gb\" in df.columns:\n",
    "        df[\"data_used_gb\"] = df[\"data_used_gb\"].clip(lower=0, upper=100)\n",
    "    if \"revenue_inr\" in df.columns:\n",
    "        df[\"revenue_inr\"] = df[\"revenue_inr\"].clip(lower=0)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "591c3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_job():\n",
    "    try:\n",
    "        log(\"Starting ETL...\")\n",
    "        if not os.path.exists(RAW_PATH):\n",
    "            log(f\"Raw file not found: {RAW_PATH}\")\n",
    "            return\n",
    "\n",
    "        # EXTRACT\n",
    "        df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "        # TRANSFORM\n",
    "        df = clean_frame(df)\n",
    "\n",
    "        # LOAD (atomic write: write tmp then rename -> avoids half-written files)\n",
    "        df.to_csv(TMP_PATH, index=False)\n",
    "        os.replace(TMP_PATH, OUT_PATH)\n",
    "\n",
    "        log(f\"ETL completed successfully. Rows written: {len(df)}.\")\n",
    "    except Exception as e:\n",
    "        log(f\"ETL failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab6a8ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-29 15:22:41] Starting ETL...\n",
      "[2025-10-29 15:22:41] Deduplicated: removed 0 duplicate row(s).\n",
      "[2025-10-29 15:22:41] ETL completed successfully. Rows written: 5.\n",
      "[2025-10-29 15:22:51] Starting ETL...\n",
      "[2025-10-29 15:22:51] Deduplicated: removed 0 duplicate row(s).\n",
      "[2025-10-29 15:22:52] ETL completed successfully. Rows written: 5.\n",
      "✅ Done. Scheduler exited after 3 runs.\n"
     ]
    }
   ],
   "source": [
    "schedule.clear()\n",
    "schedule.every(10).seconds.do(etl_job)\n",
    "\n",
    "runs = 3  # run 3 times then stop\n",
    "for _ in range(runs):\n",
    "    schedule.run_pending()\n",
    "    time.sleep(10)   # wait for the next tick\n",
    "\n",
    "print(\"✅ Done. Scheduler exited after\", runs, \"runs.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
